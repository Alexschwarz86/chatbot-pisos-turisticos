import os
import json
from datetime import datetime
from app.database import get_conversation_state, save_conversation_state
from openai import OpenAI

# Cargar la API Key de OpenAI
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def handle_transporte(user_id, user_message):
    """
    Maneja solicitudes de transporte utilizando solo GPT-4 sin APIs externas.
    """

    # ğŸ”¹ **1ï¸âƒ£ Obtener estado del usuario**
    conv_state = get_conversation_state(user_id)

    # ğŸ”¹ **2ï¸âƒ£ ConstrucciÃ³n de memoria hÃ­brida**
    historial = []
    for msg in conv_state.historial[-10:]:  
        if isinstance(msg, dict) and "usuario" in msg and "bot" in msg:
            historial.append({"role": "user", "content": str(msg["usuario"])})
            bot_response = msg["bot"]
            if isinstance(bot_response, dict):  
                bot_response = json.dumps(bot_response, ensure_ascii=False)  
            historial.append({"role": "assistant", "content": str(bot_response)})

    # ğŸ“Œ **3ï¸âƒ£ Generar el prompt para OpenAI**
    info_prompt = f"""
    ğŸ“Œ **Objetivo**: Ayudar al usuario a encontrar la mejor opciÃ³n de transporte entre ciudades como Calafell, Barcelona, Tarragona, Sitges, etc.

    **Reglas Clave**:
    1. Usa **Rodalies de CataluÃ±a (trenes)**, **buses interurbanos** y **taxis** como opciones principales.
    2. Proporciona **horarios aproximados** y **precios orientativos** si el usuario los solicita. 
   - Si no tienes datos exactos, indica que son estimaciones basadas en informaciÃ³n comÃºn.
    3. **Si el trayecto es especÃ­fico**, intenta dar la ruta mÃ¡s sencilla en el transporte disponible (indicando origen y destino).
    4. **Si no se especifica origen**, asume **Calafell** como punto de partida.
    5. Al **recomendar un transporte**, facilita la **web de referencia** solo si aÃºn no se ha dado antes al usuario.
    6. **Responde Ãºnicamente** a la pregunta formulada, sin aÃ±adir mÃ¡s detalles de los que se te piden.
    7. SÃ© conciso, **humano** y **cortÃ©s**, pero **no des informaciÃ³n innecesaria**.

    ## **Ejemplos de respuesta esperada**:
    - â€œPara ir de Calafell a Barcelona, puedes tomar el Rodalies R2 Sud cada 30 minutos por ~4,60â‚¬. Si prefieres bus, MonBus ofrece varias salidas al dÃ­a.â€
    - â€œPara un taxi entre Tarragona y Salou, el precio ronda los 20-25â‚¬.â€
    - â€œEl tren de Sitges a Calafell tarda unos 25-30 minutos y cuesta alrededor de 3,90â‚¬.â€


    ğŸ“Œ **Datos actuales en memoria:**  
    - **Origen:** {conv_state.datos_categoria.get("origen", "No definido")}
    - **Destino:** {conv_state.datos_categoria.get("destino", "No definido")}
    - **Tipo de transporte preferido:** {conv_state.datos_categoria.get("transporte", "No definido")}

    ğŸ“Œ **ConversaciÃ³n Reciente (Ventana de Tokens)**:
    {json.dumps(historial, ensure_ascii=False, indent=2)}

    ğŸ“Œ **Mensaje del usuario**:
    "{user_message}"

    ğŸ“Œ **Estructura de respuesta esperada**:
    {{
        "origen": "<ciudad de origen o 'No definido'>",
        "destino": "<ciudad de destino o 'No definido'>",
        "transporte": "<tipo de transporte preferido o 'No definido'>",
        "respuesta_al_cliente": "<respuesta con la mejor opciÃ³n de transporte>"
    }}
    """

    # ğŸ”¹ **4ï¸âƒ£ Llamada a OpenAI**
    info_response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": info_prompt}],
        max_tokens=200,
        temperature=0
    )

    print("ğŸ“Œ Prompt enviado a OpenAI:\n", info_prompt)
    response_text = info_response.choices[0].message.content.strip()
    print("ğŸ“Œ Respuesta completa de OpenAI:", response_text)

    # ğŸ”¹ **5ï¸âƒ£ Eliminar backticks antes de parsear JSON**
    if response_text.startswith("```json"):
        response_text = response_text[7:].strip()
    if response_text.endswith("```"):
        response_text = response_text[:-3].strip()

    # ğŸ”¹ **6ï¸âƒ£ Validar si la respuesta es realmente un JSON**
    try:
        result = json.loads(response_text)  
    except json.JSONDecodeError:
        print("âŒ OpenAI no devolviÃ³ un JSON vÃ¡lido. Usando respuesta normal.")
        return response_text  

    # ğŸ”¹ **7ï¸âƒ£ Actualizar y guardar la informaciÃ³n en memoria**
    if isinstance(result, dict):  
        conv_state.datos_categoria["origen"] = result.get("origen", conv_state.datos_categoria.get("origen", "No definido"))
        conv_state.datos_categoria["destino"] = result.get("destino", conv_state.datos_categoria.get("destino", "No definido"))
        conv_state.datos_categoria["transporte"] = result.get("transporte", conv_state.datos_categoria.get("transporte", "No definido"))

        # ğŸ“Œ Debugging: Verificar actualizaciÃ³n correcta
        print("ğŸ“Œ datos_categoria actualizado antes de guardar:", json.dumps(conv_state.datos_categoria, indent=4, ensure_ascii=False))

        # Guardamos la nueva informaciÃ³n en Supabase
        save_conversation_state(conv_state)
    else:
        print("âš ï¸ La respuesta de OpenAI no contiene datos vÃ¡lidos para actualizar `datos_categoria`.")

    # ğŸ”¹ **8ï¸âƒ£ Responder al usuario con la mejor opciÃ³n de transporte**
    return result["respuesta_al_cliente"]